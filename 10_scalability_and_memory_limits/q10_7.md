## Question 10.7
Imagine a web server for a simplified search engine. 

This system has 100 machines to respond to search queries, which may then call out using processSearch(string query) to another cluster of machines to actually get the result. 

The machine which responds to a given query is chosen at random, so you can not guarantee that the same machine will always respond to the same request. 

The method processSearch is very expensive. 

Design a caching mechanism for the most recent queries. 

Be sure to explain how you would update the cache when data changes.

## Solution

### Server Components

- Edge Server: processSearch(string query) を受けるサーバ. 1台. 実質的には Application LoadBalancer ?
- Query Server: processSearch(string query) を実行するサーバ. 100台. 実質的には EC2サーバ, ECSクラスタ

### Preconditions

- Input 検索文字列. 最大50文字 (50 bytes)
- Output: 下記のURL・タイトルのリスト (最大 30 件)
    * 1 URL = "https://www.google.com/" = 23 chars < 50 chars => 100 Byte
    * 1 URL's Title = 50 文字 => 50 Bytes

### Cache Design

インメモリクラスターを使う
ex. Apache Ignite or memcached

### Key, Value

- key: 検索文字列.
- value: json string => (実用の際はMessage Pack や protocol bufferを使う)
```json
[{"title": "", "url":"~~~"}, ...]
```
(27[↑] + 100[MAX url size] + 50[MAX title size]) * 30[max list] = 5,310

540 GB のオンメモリクラスターにて 100M件 (1億件) の cache key+dataの値を格納できる。

### 機能要件

- Read-Through Write-Through でキャッシュから情報を取得できなかった場合は processSearch(String query) を実行する。
- もしキャッシュのデータがfullの状態で新たなデータアクセスが発生した場合、アクセス頻度が一番少ないものを remove する
  - [Eviction Policies](https://ignite.apache.org/docs/latest/memory-configuration/eviction-policies)
  - `Random-2-LRU` eviction algorithm は 2つの access時間を保持することにより、 "one-hit wonder" problem (一発屋)を回避している
- 検索結果更新のための cache purge を行う

### 整合性

結果整合性 or 参照整合性

## Solution (Text)

### 仮定
- クエリ処理は最初に呼び出されたマシンで発生
- キャッシュしたい結果の数は多い (100万単位)
- マシン間の呼び出しは比較的酵素奥
- Query Result: Title(max 50 chars) and URL(max 200 chars) のリスト
- 人気のあるクエリは常にキャッシュに含まれる

### システム要件 (キャッシュ設計)
- キーによる効率の良い検索
- 新しいデータと置き換えるためのTTL
- クエリの結果が変わったときのために、明示的なキャッシュの更新・削除処理が必要

### Step1: 単一マシンのキャッシュを検討
- 連結リスト (データは参照される連結リストの先頭に移される。新しい項目を先頭に追加し、古い末尾のデータを削除する)
- ハッシュテーブル: データの検索・更新・削除を行える

### Step2: 複数マシンのキャッシュを検討

Option1: 各マシンに独自のキャッシュを持つ: cache hit rateが低くなることが想定。非効率である
Option2: 各マシンにキャッシュのコピーをもたせる: 100インスタンスのメモリの同期が非常に難しい。また一つのマシンに乗せることのできるメモリの容量は限られているので、データ効率が悪くなる
Option3: 各マシンにキャッシュを分散して配備する: (h[key] % instance_num) で特定の key は 結果の instance のデータに格納できる.

テキストでは明示されいないが、Option3の場合は各instance で別の連結リスト・ハッシュテーブルを持つということだろうか
